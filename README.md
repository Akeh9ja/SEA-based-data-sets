# SEA-based-data-sets

##Introduction

The linguistic capability of most Large Language Models (LLMs) like ChatGPT are dominated by English, resulting in disproportionate poor model performance for lower-resource and regional languages (Nguyen et al, 2023).

Southeast Asia (SEA) is home to more than 1,000 native languages, yet they are significantly underrepresented in the research community. These languages are often rich and diverse, but often lack the extensive dataset support available for more widely spoken languages, resulting in a stark performance gap in existing LLM applications.

In this challenge, I engage in the data collection process, specifically targeting content with a SEA context.
